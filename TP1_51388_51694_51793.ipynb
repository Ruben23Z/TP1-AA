{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4481d4fd",
   "metadata": {},
   "source": [
    "# ISEL - Aprendizagem Automática(AA)\n",
    "## Semestre de Inverno 2025/26\n",
    "# <br>\n",
    "###  <center> Trabalho Prático 1 </center>\n",
    "# </br>\n",
    "\n",
    "Trabalho realizado por:\n",
    "* <b>Ruben Zhang, número 51388 </b>\n",
    "* <b>Sofia Salgado, número 51694 </b>\n",
    "* <b>Lucas Filipe , número 51793 </b>\n",
    "\n",
    "\n",
    "<b> Turma 51D - Docente: Gonçalo Marques </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70c11c-400e-4d91-a3d7-e01ed30be605",
   "metadata": {},
   "source": [
    "## Apontamentos das Aulas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3d6c7-6fee-4bd0-ad79-60e21ddbec40",
   "metadata": {},
   "source": [
    "Dentro da inteligência artificial existe a aprendizagem automática, machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8320ac19-d22e-4261-8492-4141a3c1915e",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"https://tse3.mm.bing.net/th/id/OIP.hRNpkhGN2HL2rFcc2vFYwAHaFj?r=0&rs=1&pid=ImgDetMain&o=7&rm=3\" alt=\"Imagem 1\" width=\"25%\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6058a402-14c4-4087-8e3a-b9c867c8acff",
   "metadata": {},
   "source": "O problema XOR é que não conseguimos desenhar uma linha reta para separar os pontos positivos ((1,0) e (0,1)) dos negativos ((0,0) e (1,1)) - eles estão \"entrelaçados\" nos cantos opostos."
  },
  {
   "cell_type": "markdown",
   "id": "87c196ab-1dbc-4dc0-b795-5dff886bead4",
   "metadata": {},
   "source": [
    "As redes neuronais ficaram relativamente para trás por serem dificeis de treinar, mas entretanto, recentemente, voltaram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac44fbe9-b516-4658-8b9c-0c194bd570d9",
   "metadata": {},
   "source": [
    "#### Existem diferentes tipos de aprendizagem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3778ab5-d4ac-47ae-bf6a-d6b86f49ab55",
   "metadata": {},
   "source": [
    "`Supervisionada: `O computador aprende com exemplos que já têm as respostas certas - **Classificação** (decidir se um email é spam ou não) e **Regressão** (prever preços de casas como no Boston House Prices dataset). <br>\n",
    "`Não Supervisionada:` O computador procura padrões sem saber as respostas - agrupar dados parecidos e simplificar dados complexos. <br>\n",
    "`Semi-Supervisionada:` Mistura das duas anteriores - alguns dados têm rótulos, outros não. <br>\n",
    "`Reforço:` Os agentes aprendem ao interagir com um ambiente e a receber recompensas - como é feito nos jogos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f56931d-6a32-4915-b990-3af69fd1a2dc",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"https://tse3.mm.bing.net/th/id/OIP.0Nrd1PSXFYPVSzkAuIMNZgHaGp?r=0&rs=1&pid=ImgDetMain&o=7&rm=3\" alt=\"Imagem 1\" width=\"20%\">\n",
    "    <img src=\"https://www.pngall.com/wp-content/uploads/11/Horizontal-Line-PNG-Pic.png\" alt=\"Imagem 2\" width=\"20%\">\n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75943162-12ce-4694-b0f7-177da3c7c18f",
   "metadata": {},
   "source": [
    "Os dados podem ser espalhados em 2D, imagem da esquerda, mas também posso esticar a espiral e meter os dados espalhados em 1D, como é o caso da imagem à direita"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7122b1-63f1-4098-8cfd-489bca5dd799",
   "metadata": {},
   "source": [
    "Nós queremos treinar o modelo com um conjunto universal para todos os dados que vêm a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519beeb-9b45-4cb9-826b-efe90023c243",
   "metadata": {},
   "source": [
    "Convém sempre nós olharmos também para os dados, pois algumas vezes conseguimos distinguir os dados a olho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38dc70-5f5d-4996-a254-8e5552b99410",
   "metadata": {},
   "source": [
    "Aqueles dados que já sabemos a classe utilizamos para treinar o modelo. Não vamos classificar classes que já sabemos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526902a4-16d9-425f-9814-ae98ae5b3ebb",
   "metadata": {},
   "source": [
    "### Sistemas de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22de87f-7df0-4dad-9227-f0e496f9ef5d",
   "metadata": {},
   "source": [
    "Nós não estamos interessados em saber as classes dos dados, aqueles que já sabemos a classe utilizamos para treinar, não vamos classificar classes que já sabemos. Convém nós olharmos para os dados, porque algumas vezes conseguimos distinguir bem os dados. Queremos treinar com um conjunto de dados universal para todos os dados que vêm a seguir. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f3e92-7025-4a8c-bb6d-c8e5af7ecf2c",
   "metadata": {},
   "source": [
    "A construção do modelo de classificação é baseado num conjunto de dados para os quais se conhece a classe, e é composta pelas seguintes etapas: \n",
    "- 1: Escolher/projetar o modelo de classificação\n",
    "- 2: Treinar o modelo\n",
    "- 3: Avaliar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e470cb5-4081-49d9-8658-38a32291e89b",
   "metadata": {},
   "source": [
    "Este é um problema de aprendizagem supervisionada, os classificadores são treinados com exemplo para os quais já se sabe a classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e183662-a674-4bb7-84f9-75e73e02f24d",
   "metadata": {},
   "source": [
    "Tipos de Classificação:\n",
    "- Multi-Classe\n",
    "- Binária\n",
    "- Multi-Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8beeec-acde-425a-91b9-164be4e014b9",
   "metadata": {},
   "source": [
    "### Enquadramento Teórico e Notação\n",
    "\n",
    "Cada vetor representa uma classe e todos os vetores devem ter a mesma dimensão. <br>\n",
    "Dividir o espaço em zonas, regiões de decisão, é uma hipótese para classificar os dados, temos os pontos no espaço e depois dividimos em zonas as classes, por exemplo classe 0 fica numa zona, classe 1 noutra, etc... <br>\n",
    "Mas o que realmente vamos fazer é através de funções discriminantes, pomos a função `Gause` em cada uma das classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c553cdfc-b4e1-450d-983d-0f186236ed80",
   "metadata": {},
   "source": [
    "### Matriz de Confusão:\n",
    "\n",
    "É uma matriz quadrada, ou seja, se temos 10 classes a matriz é $ 10\\times10 $ <br>\n",
    "A matriz é composta só por probabilidade, pois cada classe tem probabilidades. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10112505-a407-452c-8a0d-d10336a074ba",
   "metadata": {},
   "source": [
    "Se somar todos os valores na matriz de confusão tem de dar 1, 100%, tenho todos os pontos na matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682e998-588a-4de0-886d-e360c04f5fbe",
   "metadata": {},
   "source": [
    "$A_{3 \\times 4}$\n",
    "\n",
    "$$A = \\begin{bmatrix}\n",
    "-8 & 1 & 5 & -4 & -1 \\\\\n",
    "20 & 0 & -9 & 4 & -9 \\\\\n",
    "-25 & 0 & 3 & 0 & 11\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8e96b5-ae83-42d0-afa2-a378bc23602a",
   "metadata": {},
   "source": [
    "Temos de analisar o tipo de erros que estamos a ter, se o classificador, por exemplo, está a confundir malas com saias ou com calças, alguma coisa está mal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ef436-11a6-4659-a093-b99441d63f6f",
   "metadata": {},
   "source": [
    "A matriz de confusão não nos diz a probabilidade total de erro, faltam as probabilidades à priori de cada classe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed73f63-ab37-49e2-b252-75d9df03248f",
   "metadata": {},
   "source": [
    "Probabilidade total de erro:\n",
    "$$ \\sum_{i}{} (1-p_i) \\times p(w_i) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247195b-b7e0-4e8a-9d39-d4c4949558e4",
   "metadata": {},
   "source": [
    "A matriz de confusão do scikit-learn é não normalizada, onde somamos as linhas e temos todos os pontos de uma classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de743a2a-4a1c-42b4-99f8-2a55c84ce4a8",
   "metadata": {},
   "source": [
    "### ====== Classificação Binária ======"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599fb3fe-243a-40bb-890e-80eea1e216b5",
   "metadata": {},
   "source": [
    "Chamam-se às duas classes positivos e negativos ($w_p, w_n$) e os que nos interessam são os positivos. O que eu não quero são os falsos positivos e na medicina o que não quero são os falsos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f00e80-e93f-45c3-9104-1e9ec4801a80",
   "metadata": {},
   "source": [
    "#### Métricas de desempenho - Classificação Binária"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f42b9-933b-41f5-b1f2-416d88424dea",
   "metadata": {},
   "source": [
    "Se somar a primeira linha da matriz tenho o número total de exemplos positivos e se somar a segunda linha da matriz tenho o número total de exemplos negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e2747-82b2-45ce-8570-6bdc0962a25f",
   "metadata": {},
   "source": [
    "$$ Recall = \\frac {TP}{TP + FN} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7cbf1-02d3-4bfb-9338-f9645d9afd80",
   "metadata": {},
   "source": [
    "$$ Precision = \\frac {TP}{TP+FP} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c262dd4-30f3-4118-826d-1e7accfac261",
   "metadata": {},
   "source": [
    "Para classificadores binários podemos calibrá-lo, ou seja, tornar o classificador mais conservador, só diz que é positivo raramente ou se tiver mesmo a certeza da sua resposta, ou liberal, é positivo maior parte das vezes. <br>\n",
    "Assim é mais fácil meter o Recall a 1 e a Precision igual a 1, mas os dois ao mesmo tempo é mais dificil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9fd76-5ca5-497a-bcdb-3185721b7894",
   "metadata": {},
   "source": [
    "#### Curvas de ROC\n",
    "\n",
    "Com as curvas de ROC temos uma ideia melhor de como o classificador está a comportar-se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d522191-d91e-4278-ab95-e1541fbf4958",
   "metadata": {},
   "source": [
    "Os classificadores na diagonal das curvas de ROC não servem para nada, são para descartar, os classificadores no canto inferior direito estão a falhar mais que o aleatório, logo é só inverter o pensamento do classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c353d90-f4a8-4241-b347-b735e2a06a1d",
   "metadata": {},
   "source": [
    "Temos uma função e se essa função for maior que um linear então é da classe dos positivos, senão é da classe dos negativos. Onde meter este linear depende do contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd409efb-5d80-44ce-a1d9-380b3e321a10",
   "metadata": {},
   "source": [
    "Estas curvas são ferramentas fundamentais para ver como o classificador está a comportar-se."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15577908-1049-4f42-8e63-aac9a1d04c67",
   "metadata": {},
   "source": [
    "#### ====== Validação Cruzada ======\n",
    "\n",
    "Em vez de dividir por 2 os dados, vamos cortar às fatias, K-fold. Nos exemplos dos slides é cortado em 5. Primeiro vamos ver a estratégia, cortamos às fatias, depois escolhemos uma delas e usamos para treino, depois escolhemos outra fatia e usamos para treino.... repitimos K vezes, sendo K o número de fatias, mas assim temos K classificadores também."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4b2e6-8802-401c-80b9-c16d386d5abc",
   "metadata": {},
   "source": [
    "Se temos modelos complexos, com muitos pensamentos, temos de ter milhoes de exemplos, como é o caso do ChatGPT. <br>\n",
    "Para ajustar bem o modelo, temos de ter muitos exemplos e nem sempre isso é possível."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3392b3-c1b4-4634-8b87-980b73b1aa22",
   "metadata": {},
   "source": [
    "##### Desvantagens:\n",
    "- Temos de treinar K vezes;\n",
    "- Não nos vai dar o modelo, vamos ter que treinar o modelo mais tarde com todos os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccfb5b7-c434-4ccf-9a2a-98eaea9b2440",
   "metadata": {},
   "source": [
    "##### Vantagens:\n",
    "- Em vez de termos apenas uma matriz de confusão, temos K matrizes, vai dar-nos então o mínimo, máximo, a média, etc, temos uma estimativa mais precisa\n",
    "- Não há risco de termos encontrado um conjunto mau ou dificil, não há exemplos faceis ou dificeis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744a386-e22b-4c58-85c2-db216f9e5062",
   "metadata": {},
   "source": [
    "##### Leave one out\n",
    "Deixamos um ponto de fora e avaliamos, mas se tivermos 1000 pontos, temos de treinar e avaliar 1000 vezes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0239478-4993-4316-b274-026afa841770",
   "metadata": {},
   "source": [
    "Ao adaptar os dados, vai haver outros parametros que vão variar os dados, hiper-parametros. Eu posso dividir o meu dataset em fatias, usar e treinar com um determinado hiper-parametro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d985fbb-8739-4652-aa0f-e4508bc5e194",
   "metadata": {},
   "source": [
    "o cross val predict mete cá para fora a classificação de todo o conjunto de teste. Tendo a classe verdadeira e a classe estimada temos então a matriz de confusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a4a93-5c2c-456d-8a98-9b10b3ccca48",
   "metadata": {},
   "source": [
    "A cada iteração alteramos minimamente os parametros da função até reduzirmos a função de custo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25cc9d6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import average_precision_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ],
   "id": "a36a3e0e4fb5480d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c466e44e8b8b3343",
   "metadata": {},
   "source": [
    "### Objetivos:\n",
    "1. Obter e ler a informação do ficheiro pickle\n",
    "2. Normalizar os valores obtidos\n",
    "3. Verificar a vantagem da normalização dos dados\n",
    "4. Escolher dois classificadores binarios\n",
    "5. Treinar os classificadores\n",
    "6. Testar os classificadores\n",
    "7. Avaliar os classificadores com base em métricas, calibando caso se verifique necessário\n",
    "8. Realizar um estudo comparativo dos desempenho dos diferentes classificadores"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Carregar dados do ficheiro pickle\n",
    "data = pickle.load(open('pimaDiabetes.p', 'rb'))\n",
    "X = data['data']  # Características\n",
    "y = data['target']  # Classes (0=não diabetes, 1=diabetes)\n",
    "\n",
    "print(\"-----------------------------------Dados-----------------------------------------------------------\")\n",
    "print(f\"Número total de exemplos: {X.shape[0]}\")\n",
    "print(f\"Número de características: {X.shape[1]}\")\n",
    "print(f\"Exemplos sem diabetes (classe 0): {np.sum(y==0)}\")\n",
    "print(f\"Exemplos com diabetes (classe 1): {np.sum(y==1)}\")\n"
   ],
   "id": "f85be0a39e45d3f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# HISTOGRAMAS DAS CARACTERÍSTICAS DO DATASET\n",
    "\n",
    "# Nomes das features (correspondentes ao dataset Pima Diabetes)\n",
    "feature_names_pt = ['Gravidezes', 'Glicose', 'Pressão Arterial', 'Espessura Dobra',\n",
    "                    'Insulina', 'BMI', 'Pedigree', 'Idade']\n",
    "\n",
    "# Criar figura com 8 subplots (2 linhas x 4 colunas)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Configurações de cores para os histogramas\n",
    "colors = ['steelblue', 'steelblue', 'steelblue', 'steelblue',\n",
    "          'steelblue', 'steelblue', 'steelblue', 'steelblue']\n",
    "\n",
    "# Criar histogramas para cada feature\n",
    "for i in range(X.shape[1]):\n",
    "    axes[i].hist(X[:, i], bins=30, color=colors[i], edgecolor='black', alpha=0.7)\n",
    "    axes[i].set_title(feature_names_pt[i], fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel('Frequência', fontsize=10)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    axes[i].spines['top'].set_visible(False)\n",
    "    axes[i].spines['right'].set_visible(False)\n",
    "\n",
    "# Ajustar layout\n",
    "plt.suptitle('Distribuição das Características - Dataset Pima Diabetes', \n",
    "             fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "51451c8764f0365c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e679692a-12e3-4144-adad-09cb09a64a20",
   "metadata": {},
   "source": [
    "### Desenvolvimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0582e94-f839-4f91-9d11-af1fc1c83210",
   "metadata": {},
   "source": [
    "#### 1. MODELOS DE CLASSIFICAÇÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cf3c7-273c-423b-ac35-b994859bafb9",
   "metadata": {},
   "source": [
    "#####  (a) escolher 3 classificadores binários"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseado nos slides de Discriminantes Logísticos e sistemas de classificação\n",
    "# Escolhemos 3 classificadores:\n",
    "\n",
    "# 1. RandomForestClassifier (obrigatório)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 2. Discriminante Logístico (visto nos slides AA-DiscLogistV2.pdf)\n",
    "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# 3. Naive Bayes Gaussiano (visto nos slides AA-SistClass.pdf)\n",
    "nb = GaussianNB()\n",
    "\n",
    "print(\"Classificadores escolhidos:\")\n",
    "print(\"1. RandomForestClassifier\")\n",
    "print(\"2. Logistic Regression (Discriminante Logístico)\")\n",
    "print(\"3. GaussianNB (Naive Bayes)\")\n",
    "print()"
   ],
   "id": "71dd89be5bccbc89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### (b) Treinar os classificadores - escolha dos hiperparâmetros",
   "id": "e25efacde10b38f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Para o Random Forest, vamos testar diferentes valores de n_estimators\n",
    "# Baseado no conceito de validação cruzada dos slides AP-Xvalida.pdf\n",
    "\n",
    "print(\"Testar hiperparâmetros do RandomForest...\")\n",
    "# Testar diferentes números de árvores\n",
    "n_trees_options = [10, 50, 100, 200]\n",
    "best_score = 0\n",
    "best_n_trees = 10\n",
    "\n",
    "for n_trees in n_trees_options:\n",
    "    rf_temp = RandomForestClassifier(n_estimators=n_trees, random_state=42)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(rf_temp, X, y, cv=kfold)\n",
    "    mean_score = np.mean(scores)\n",
    "    print(f\"  n_estimators={n_trees}, Acurácia média = {mean_score:.4f}\")\n",
    "    \n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_n_trees = n_trees\n",
    "\n",
    "print(f\"\\nMelhor n_estimators: {best_n_trees}\\n\")\n",
    "\n",
    "# Atualizar o classificador com o melhor parâmetro\n",
    "rf = RandomForestClassifier(n_estimators=best_n_trees, random_state=42)"
   ],
   "id": "fff6f7cb23cca454",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### (c) Metodologia de treino/teste apropriada",
   "id": "88c17041fa799ee4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseado nos slides AP-Xvalida.pdf\n",
    "# Usar StratifiedKFold com 5 folds para manter proporção de classes\n",
    "# (há desbalanceamento: 500 não-diabetes vs 268 diabetes)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"Metodologia escolhida: Stratified K-Fold Cross Validation\")\n",
    "print(\"Número de folds: 5\")\n",
    "print(\"Justificação: Mantém a proporção de classes em cada fold,\")\n",
    "print(\"             importante porque há desbalanceamento nos dados.\\n\")\n",
    "\n",
    "\n",
    "# Treinar e obter predições para todos os classificadores\n",
    "#Utilizar o cross_val_predict treinar o classificador internamente para avaliar com a estratificação, sendo descartado o treino\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\n1. RandomForestClassifier:\")\n",
    "scores_rf = cross_val_score(rf, X, y, cv=kfold)\n",
    "results_rf = cross_val_predict(rf, X, y, cv=kfold)\n",
    "print(f\"   Accuracy por fold: {scores_rf}\")\n",
    "print(f\"   Accuracy média: {np.mean(scores_rf):.4f}\")\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"\\n2. Logistic Regression:\")\n",
    "scores_lr = cross_val_score(logreg, X, y, cv=kfold)\n",
    "results_lr = cross_val_predict(logreg, X, y, cv=kfold)\n",
    "print(f\"   Accuracy por fold: {scores_lr}\")\n",
    "print(f\"   Accuracy média: {np.mean(scores_lr):.4f}\")\n",
    "\n",
    "# Naive Bayes\n",
    "print(\"\\n3. GaussianNB:\")\n",
    "scores_nb = cross_val_score(nb, X, y, cv=kfold)\n",
    "results_nb = cross_val_predict(nb, X, y, cv=kfold)\n",
    "print(f\"   Accuracy por fold: {scores_nb}\")\n",
    "print(f\"   Accuracy média: {np.mean(scores_nb):.4f}\")\n",
    "print()"
   ],
   "id": "2b96d64f5b804568",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### (d) Métricas apropriadas e calibração",
   "id": "910b3dfdaa72334c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseado nos slides AP-Xvalida.pdf e AA-SistClass.pdf\n",
    "# Para classificação binária com classes desbalanceadas, usar:\n",
    "# - Matriz de confusão\n",
    "# - Precision, Recall, F1-score\n",
    "# - Curvas ROC e AUC\n",
    "\n",
    "print(\"\\n--- RANDOM FOREST ---\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "cm_rf = confusion_matrix(y, results_rf)\n",
    "print(cm_rf)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y, results_rf, target_names=['Não-Diabetes', 'Diabetes']))\n",
    "\n",
    "print(\"\\n--- LOGISTIC REGRESSION ---\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "cm_lr = confusion_matrix(y, results_lr)\n",
    "print(cm_lr)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y, results_lr, target_names=['Não-Diabetes', 'Diabetes']))\n",
    "\n",
    "print(\"\\n--- NAIVE BAYES ---\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "cm_nb = confusion_matrix(y, results_nb)\n",
    "print(cm_nb)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y, results_nb, target_names=['Não-Diabetes', 'Diabetes']))\n",
    "\n",
    "# Curvas ROC (baseado nos slides AP-Xvalida.pdf)\n",
    "print(\"\\nCalculando AUC (Area Under ROC Curve)...\")\n",
    "\n",
    "# Treinar modelos para obter probabilidades (para curvas ROC)\n",
    "rf_full = RandomForestClassifier(n_estimators=best_n_trees, random_state=42)\n",
    "rf_full.fit(X, y)\n",
    "proba_rf = cross_val_predict(rf_full, X, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "\n",
    "logreg_full = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg_full.fit(X, y)\n",
    "proba_lr = cross_val_predict(logreg_full, X, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "\n",
    "nb_full = GaussianNB()\n",
    "nb_full.fit(X, y)\n",
    "proba_nb = cross_val_predict(nb_full, X, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "\n",
    "auc_rf = roc_auc_score(y, proba_rf)\n",
    "auc_lr = roc_auc_score(y, proba_lr)\n",
    "auc_nb = roc_auc_score(y, proba_nb)\n",
    "\n",
    "print(f\"AUC - Random Forest: {auc_rf:.4f}\")\n",
    "print(f\"AUC - Logistic Regression: {auc_lr:.4f}\")\n",
    "print(f\"AUC - Naive Bayes: {auc_nb:.4f}\")\n",
    "print()\n",
    "\n",
    "# Visualizar curvas ROC\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y, proba_rf)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y, proba_lr)\n",
    "fpr_nb, tpr_nb, _ = roc_curve(y, proba_nb)\n",
    "\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC={auc_rf:.3f})')\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC={auc_lr:.3f})')\n",
    "plt.plot(fpr_nb, tpr_nb, label=f'Naive Bayes (AUC={auc_nb:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Aleatório')\n",
    "\n",
    "plt.xlabel('Taxa de Falsos Positivos (FP-rate)')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TP-rate)')\n",
    "plt.title('Curvas ROC')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ],
   "id": "14ac21fe8db43916",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mais Gráficos",
   "id": "efae30b0e1ab1be9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GRÁFICO 1: MATRIZES DE CONFUSÃO VISUALIZADAS",
   "id": "b83ce2eb22c23eb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Treinar modelos para obter probabilidades (para curvas ROC e Precision-Recall)\n",
    "rf_full = RandomForestClassifier(n_estimators=best_n_trees, random_state=42)\n",
    "rf_full.fit(X, y)\n",
    "proba_rf = cross_val_predict(rf_full, X, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "\n",
    "logreg_full = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg_full.fit(X, y)\n",
    "proba_lr = cross_val_predict(logreg_full, X, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "\n",
    "nb_full = GaussianNB()\n",
    "nb_full.fit(X, y)\n",
    "proba_nb = cross_val_predict(nb_full, X, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Random Forest\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, \n",
    "                                  display_labels=['Não-Diabetes', 'Diabetes'])\n",
    "disp_rf.plot(ax=axes[0], cmap='Blues', values_format='d')\n",
    "axes[0].set_title('Random Forest\\nMatriz de Confusão')\n",
    "axes[0].grid(False)\n",
    "\n",
    "# Logistic Regression\n",
    "disp_lr = ConfusionMatrixDisplay(confusion_matrix=cm_lr, \n",
    "                                  display_labels=['Não-Diabetes', 'Diabetes'])\n",
    "disp_lr.plot(ax=axes[1], cmap='Greens', values_format='d')\n",
    "axes[1].set_title('Logistic Regression\\nMatriz de Confusão')\n",
    "axes[1].grid(False)\n",
    "\n",
    "# Naive Bayes\n",
    "disp_nb = ConfusionMatrixDisplay(confusion_matrix=cm_nb, \n",
    "                                  display_labels=['Não-Diabetes', 'Diabetes'])\n",
    "disp_nb.plot(ax=axes[2], cmap='Oranges', values_format='d')\n",
    "axes[2].set_title('Naive Bayes\\nMatriz de Confusão')\n",
    "axes[2].grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "732a2b720993e65d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### GRÁFICO 2: CURVAS PRECISION-RECALL",
   "id": "9826b1baaeaff5e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular curvas Precision-Recall (baseado nos slides AP-Xvalida.pdf)\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y, proba_rf)\n",
    "precision_lr, recall_lr, _ = precision_recall_curve(y, proba_lr)\n",
    "precision_nb, recall_nb, _ = precision_recall_curve(y, proba_nb)\n",
    "\n",
    "# Calcular Average Precision Score\n",
    "ap_rf = average_precision_score(y, proba_rf)\n",
    "ap_lr = average_precision_score(y, proba_lr)\n",
    "ap_nb = average_precision_score(y, proba_nb)\n",
    "\n",
    "print(f\"Average Precision - Random Forest: {ap_rf:.4f}\")\n",
    "print(f\"Average Precision - Logistic Regression: {ap_lr:.4f}\")\n",
    "print(f\"Average Precision - Naive Bayes: {ap_nb:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(recall_rf, precision_rf, 'b-', linewidth=2.5, \n",
    "         label=f'Random Forest (AP={ap_rf:.3f})')\n",
    "plt.plot(recall_lr, precision_lr, 'g-', linewidth=2.5, \n",
    "         label=f'Logistic Regression (AP={ap_lr:.3f})')\n",
    "plt.plot(recall_nb, precision_nb, 'orange', linewidth=2.5, \n",
    "         label=f'Naive Bayes (AP={ap_nb:.3f})')\n",
    "\n",
    "# Linha de baseline (proporção de positivos)\n",
    "baseline = np.sum(y) / len(y)\n",
    "plt.axhline(y=baseline, color='k', linestyle='--', linewidth=2, \n",
    "            label=f'Baseline (proporção diabetes={baseline:.3f})')\n",
    "\n",
    "plt.xlabel('Recall (Taxa de Verdadeiros Positivos)', fontsize=12)\n",
    "plt.ylabel('Precision (Precisão)', fontsize=12)\n",
    "plt.title('Curvas Precision-Recall - Comparação dos Classificadores', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ],
   "id": "cf4a3e7438afd57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### GRÁFICO 3: COMPARAÇÃO DE MÉTRICAS EM BARRAS",
   "id": "479b706bc75641e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extrair métricas dos relatórios\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "metrics_data = {\n",
    "    'Random Forest': {\n",
    "        'Acurácia': np.mean(scores_rf),\n",
    "        'Precision': precision_score(y, results_rf),\n",
    "        'Recall': recall_score(y, results_rf),\n",
    "        'F1-Score': f1_score(y, results_rf),\n",
    "        'AUC': auc_rf\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'Acurácia': np.mean(scores_lr),\n",
    "        'Precision': precision_score(y, results_lr),\n",
    "        'Recall': recall_score(y, results_lr),\n",
    "        'F1-Score': f1_score(y, results_lr),\n",
    "        'AUC': auc_lr\n",
    "    },\n",
    "    'Naive Bayes': {\n",
    "        'Acurácia': np.mean(scores_nb),\n",
    "        'Precision': precision_score(y, results_nb),\n",
    "        'Recall': recall_score(y, results_nb),\n",
    "        'F1-Score': f1_score(y, results_nb),\n",
    "        'AUC': auc_nb\n",
    "    }\n",
    "}\n",
    "\n",
    "# Criar gráfico de barras agrupadas\n",
    "metrics_names = ['Acurácia', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "classifiers = list(metrics_data.keys())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.25\n",
    "\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    values = [metrics_data[classifier][metric] for metric in metrics_names]\n",
    "    offset = width * (i - 1)\n",
    "    bars = ax.bar(x + offset, values, width, label=classifier, alpha=0.8)\n",
    "    \n",
    "    # Adicionar valores no topo das barras\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Métricas', fontsize=12)\n",
    "ax.set_ylabel('Valor', fontsize=12)\n",
    "ax.set_title('Comparação de Métricas de Desempenho', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_names)\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9b4b2c2a28b3883a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### GRÁFICO 4: HEATMAP DAS MATRIZES DE CONFUSÃO NORMALIZADAS",
   "id": "89241f9550e0ea66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Normalizar matrizes de confusão\n",
    "cm_rf_norm = cm_rf.astype('float') / cm_rf.sum(axis=1)[:, np.newaxis]\n",
    "cm_lr_norm = cm_lr.astype('float') / cm_lr.sum(axis=1)[:, np.newaxis]\n",
    "cm_nb_norm = cm_nb.astype('float') / cm_nb.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Random Forest\n",
    "sns.heatmap(cm_rf_norm, annot=True, fmt='.2%', cmap='Blues', \n",
    "            xticklabels=['Não-Diabetes', 'Diabetes'],\n",
    "            yticklabels=['Não-Diabetes', 'Diabetes'],\n",
    "            ax=axes[0], cbar_kws={'label': 'Proporção'})\n",
    "axes[0].set_title('Random Forest\\nMatriz Normalizada', fontweight='bold')\n",
    "axes[0].set_ylabel('Classe Verdadeira')\n",
    "axes[0].set_xlabel('Classe Predita')\n",
    "\n",
    "# Logistic Regression\n",
    "sns.heatmap(cm_lr_norm, annot=True, fmt='.2%', cmap='Greens', \n",
    "            xticklabels=['Não-Diabetes', 'Diabetes'],\n",
    "            yticklabels=['Não-Diabetes', 'Diabetes'],\n",
    "            ax=axes[1], cbar_kws={'label': 'Proporção'})\n",
    "axes[1].set_title('Logistic Regression\\nMatriz Normalizada', fontweight='bold')\n",
    "axes[1].set_ylabel('Classe Verdadeira')\n",
    "axes[1].set_xlabel('Classe Predita')\n",
    "\n",
    "# Naive Bayes\n",
    "sns.heatmap(cm_nb_norm, annot=True, fmt='.2%', cmap='Oranges', \n",
    "            xticklabels=['Não-Diabetes', 'Diabetes'],\n",
    "            yticklabels=['Não-Diabetes', 'Diabetes'],\n",
    "            ax=axes[2], cbar_kws={'label': 'Proporção'})\n",
    "axes[2].set_title('Naive Bayes\\nMatriz Normalizada', fontweight='bold')\n",
    "axes[2].set_ylabel('Classe Verdadeira')\n",
    "axes[2].set_xlabel('Classe Predita')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e0783e400ec168b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### (e) Estudo comparativo",
   "id": "7daf65c8e966de40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"-\" * 60)\n",
    "print(f\"{'Classificador':<25} {'accuracy':<12} {'AUC':<12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Random Forest':<25} {np.mean(scores_rf):.4f}       {auc_rf:.4f}\")\n",
    "print(f\"{'Logistic Regression':<25} {np.mean(scores_lr):.4f}       {auc_lr:.4f}\")\n",
    "print(f\"{'Naive Bayes':<25} {np.mean(scores_nb):.4f}       {auc_nb:.4f}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Determinar o melhor classificador\n",
    "best_classifier = None\n",
    "best_auc = max(auc_rf, auc_lr, auc_nb)\n",
    "\n",
    "if best_auc == auc_rf:\n",
    "    best_classifier = \"Random Forest\"\n",
    "elif best_auc == auc_lr:\n",
    "    best_classifier = \"Logistic Regression\"\n",
    "else:\n",
    "    best_classifier = \"Naive Bayes\"\n",
    "\n",
    "print(f\"\\nMelhor classificador (baseado em AUC): {best_classifier}\")\n"
   ],
   "id": "a8694d77f5b53615",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ANÁLISE:\n",
    "- A accuracy mede a percentagem total de acertos\n",
    "- AUC mede a capacidade de discriminar entre classes\n",
    "- Para dados desbalanceados, AUC é mais informativo que accuracy\n",
    "- Valores de Recall são importantes em diagnóstico médico\n",
    "  (evitar falsos negativos - não detetar diabetes quando existe)\n"
   ],
   "id": "d0b75657f33d4cb6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. PRÉ-PROCESSAMENTO - NORMALIZAÇÃO",
   "id": "a365c7a0b83e97c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Baseado nos slides, normalizar significa transformar dados para\n",
    "# média nula e variância unitária (StandardScaler)\n",
    "\n",
    "# Normalizar dados\n",
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "#Treinar classificadores com dados normalizados\n",
    "\n",
    "# Random Forest com dados normalizados\n",
    "scores_rf_norm = cross_val_score(rf, X_norm, y, cv=kfold)\n",
    "results_rf_norm = cross_val_predict(rf, X_norm, y, cv=kfold)\n",
    "proba_rf_norm = cross_val_predict(rf, X_norm, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "auc_rf_norm = roc_auc_score(y, proba_rf_norm)\n",
    "ap_rf_norm = average_precision_score(y, proba_rf_norm)\n",
    "\n",
    "print(f\"Random Forest (normalizado): Accuracy = {np.mean(scores_rf_norm):.4f}, AUC = {auc_rf_norm:.4f}, Average Precision={ap_rf_norm:.4f}\")\n",
    "\n",
    "# Logistic Regression com dados normalizados\n",
    "scores_lr_norm = cross_val_score(logreg, X_norm, y, cv=kfold)\n",
    "results_lr_norm = cross_val_predict(logreg, X_norm, y, cv=kfold)\n",
    "proba_lr_norm = cross_val_predict(logreg, X_norm, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "auc_lr_norm = roc_auc_score(y, proba_lr_norm)\n",
    "ap_lr_norm = average_precision_score(y, proba_lr_norm)\n",
    "\n",
    "print(f\"Logistic Regression (normalizado): Accuracy = {np.mean(scores_lr_norm):.4f}, AUC = {auc_lr_norm:.4f}, Average Precision={ap_lr_norm:.4f}\")\n",
    "\n",
    "# Naive Bayes com dados normalizados\n",
    "scores_nb_norm = cross_val_score(nb, X_norm, y, cv=kfold)\n",
    "results_nb_norm = cross_val_predict(nb, X_norm, y, cv=kfold)\n",
    "proba_nb_norm = cross_val_predict(nb, X_norm, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "auc_nb_norm = roc_auc_score(y, proba_nb_norm)\n",
    "ap_nb_norm = average_precision_score(y, proba_nb_norm)\n",
    "\n",
    "print(f\"Naive Bayes (normalizado): Accuracy = {np.mean(scores_nb_norm):.4f}, AUC = {auc_nb_norm:.4f} , Average Precision={ap_nb_norm:.4f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Comparação\n",
    "print(\"COMPARAÇÃO: Dados Originais vs Normalizados\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Classificador':<25} {'Original (AUC)':<20} {'Normalizado (AUC)':<20}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Random Forest':<25} {auc_rf:.4f}{'':<20}{auc_rf_norm:.4f}\")\n",
    "print(f\"{'Logistic Regression':<24} {auc_lr:.4f}{'':<20}{auc_lr_norm:.4f}\")\n",
    "print(f\"{'Naive Bayes':<28} {auc_nb:.4f}{'':<20}{auc_nb_norm:.4f}\")\n",
    "print(\"-\" * 70)\n",
    "print()\n"
   ],
   "id": "684757050d2e2225",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. CALIBRAÇÃO DOS MODELOS",
   "id": "70369adb2a9897d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calibração com o metodo sigmoid, que é ideal para uma pequena quantidade de dados\n",
    "#Calibração dos modelos com os dados normalizados\n",
    "\n",
    "cal_rf_norm = CalibratedClassifierCV(rf, cv=5, method='sigmoid')\n",
    "cal_proba_rf_norm = cross_val_predict(cal_rf_norm, X_norm, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "cal_auc_rf_norm = roc_auc_score(y, cal_proba_rf_norm)\n",
    "cal_ap_rf_norm = average_precision_score(y, cal_proba_rf_norm)\n",
    "\n",
    "# Logistic Regression com dados normalizados\n",
    "cal_lr_norm = CalibratedClassifierCV(logreg, cv=5, method='sigmoid')\n",
    "cal_proba_lr_norm = cross_val_predict(cal_lr_norm, X_norm, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "cal_auc_lr_norm = roc_auc_score(y, cal_proba_lr_norm)\n",
    "cal_ap_lr_norm = average_precision_score(y, cal_proba_lr_norm)\n",
    "\n",
    "# Naive Bayes com dados normalizados\n",
    "cal_nb_norm = CalibratedClassifierCV(nb, cv=5, method='sigmoid')\n",
    "cal_proba_nb_norm = cross_val_predict(cal_nb_norm, X_norm, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "cal_auc_nb_norm = roc_auc_score(y, cal_proba_nb_norm)\n",
    "cal_ap_nb_norm = average_precision_score(y, cal_proba_nb_norm)\n",
    "\n",
    "print(\"\\n RESULTADOS COM CALIBRAÇÃO\")\n",
    "print(f\"RF (cal): AUC={cal_auc_rf_norm:.4f}, AP={cal_ap_rf_norm:.4f}\")\n",
    "print(f\"LR (cal): AUC={cal_auc_lr_norm:.4f}, AP={cal_ap_lr_norm:.4f}\")\n",
    "print(f\"NB (cal): AUC={cal_auc_nb_norm:.4f}, AP={cal_ap_nb_norm:.4f}\")\n",
    "\n",
    "print(\"\\n\\nTABELA FINAL\")\n",
    "print(\"-\" * 89)\n",
    "print(f\"{'Modelo':<20}{'AUC_NORM':<15}{'AUC_NORM_CAL':<15}{'AP_NORM':<15}{'AP_NORM_CAL':<15}\")\n",
    "print(\"-\" * 89)\n",
    "print(\n",
    "    f\"{'Random Forest':<20}{auc_rf_norm:.4f}{'':<13}{cal_auc_rf_norm:.4f}{'':<13}{ap_rf_norm:.4f}{'':<13}{cal_ap_rf_norm:.4f}\")\n",
    "print(\n",
    "    f\"{'Logistic Reg.':<25}{auc_lr_norm:.4f}{'':<13}{cal_auc_lr_norm:.4f}{'':<13}{ap_lr_norm:.4f}{'':<13}{cal_ap_lr_norm:.4f}\")\n",
    "print(\n",
    "    f\"{'Naive Bayes':<23}{auc_nb_norm:.4f}{'':<13}{cal_auc_nb_norm:.4f}{'':<13}{ap_nb_norm:.4f}{'':<13}{cal_ap_nb_norm:.4f}\")\n",
    "print(\"-\" * 89)\n",
    "\n",
    "#   PLOTS PARA OS 3 MODELOS: RF, LR, NB\n",
    "#   PLOTS: ROC, PR, CALIBRATION\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.suptitle(\"Comparação de Modelos — ROC, Precision-Recall e Calibration Curves\",\n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1 — RANDOM FOREST\n",
    "# ROC\n",
    "plt.subplot(3, 3, 1)\n",
    "fpr_raw, tpr_raw, _ = roc_curve(y, proba_rf_norm)\n",
    "fpr_cal, tpr_cal, _ = roc_curve(y, cal_proba_rf_norm)\n",
    "plt.plot(fpr_raw, tpr_raw, label=\"RF raw\", color=\"red\")\n",
    "plt.plot(fpr_cal, tpr_cal, label=\"RF calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC — Random Forest\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Precision–Recall\n",
    "plt.subplot(3, 3, 2)\n",
    "prec_raw, rec_raw, _ = precision_recall_curve(y, proba_rf_norm)\n",
    "prec_cal, rec_cal, _ = precision_recall_curve(y, cal_proba_rf_norm)\n",
    "plt.plot(rec_raw, prec_raw, label=\"RF raw\", color=\"red\")\n",
    "plt.plot(rec_cal, prec_cal, label=\"RF calibrado\", color=\"blue\")\n",
    "plt.title(\"PR Curve — Random Forest\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Calibration Curve\n",
    "plt.subplot(3, 3, 3)\n",
    "pt_raw, pp_raw = calibration_curve(y, proba_rf_norm, n_bins=10)\n",
    "pt_cal, pp_cal = calibration_curve(y, cal_proba_rf_norm, n_bins=10)\n",
    "plt.plot(pp_raw, pt_raw, \"s-\", label=\"RF raw\", color=\"red\")\n",
    "plt.plot(pp_cal, pt_cal, \"o-\", label=\"RF calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"Calibration — Random Forest\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# 2 — LOGISTIC REGRESSION\n",
    "# ROC\n",
    "plt.subplot(3, 3, 4)\n",
    "fpr_raw, tpr_raw, _ = roc_curve(y, proba_lr_norm)\n",
    "fpr_cal, tpr_cal, _ = roc_curve(y, cal_proba_lr_norm)\n",
    "plt.plot(fpr_raw, tpr_raw, label=\"LR raw\", color=\"red\")\n",
    "plt.plot(fpr_cal, tpr_cal, label=\"LR calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC — Logistic Regression\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Precision–Recall\n",
    "plt.subplot(3, 3, 5)\n",
    "prec_raw, rec_raw, _ = precision_recall_curve(y, proba_lr_norm)\n",
    "prec_cal, rec_cal, _ = precision_recall_curve(y, cal_proba_lr_norm)\n",
    "plt.plot(rec_raw, prec_raw, label=\"LR raw\", color=\"red\")\n",
    "plt.plot(rec_cal, prec_cal, label=\"LR calibrado\", color=\"blue\")\n",
    "plt.title(\"PR Curve — Logistic Regression\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Calibration Curve\n",
    "plt.subplot(3, 3, 6)\n",
    "pt_raw, pp_raw = calibration_curve(y, proba_lr_norm, n_bins=10)\n",
    "pt_cal, pp_cal = calibration_curve(y, cal_proba_lr_norm, n_bins=10)\n",
    "plt.plot(pp_raw, pt_raw, \"s-\", label=\"LR raw\", color=\"red\")\n",
    "plt.plot(pp_cal, pt_cal, \"o-\", label=\"LR calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"Calibration — Logistic Regression\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# 3 — NAIVE BAYES\n",
    "# ROC\n",
    "plt.subplot(3, 3, 7)\n",
    "fpr_raw, tpr_raw, _ = roc_curve(y, proba_nb_norm)\n",
    "fpr_cal, tpr_cal, _ = roc_curve(y, cal_proba_nb_norm)\n",
    "plt.plot(fpr_raw, tpr_raw, label=\"NB raw\", color=\"red\")\n",
    "plt.plot(fpr_cal, tpr_cal, label=\"NB calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC — Naive Bayes\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Precision–Recall\n",
    "plt.subplot(3, 3, 8)\n",
    "prec_raw, rec_raw, _ = precision_recall_curve(y, proba_nb_norm)\n",
    "prec_cal, rec_cal, _ = precision_recall_curve(y, cal_proba_nb_norm)\n",
    "plt.plot(rec_raw, prec_raw, label=\"NB raw\", color=\"red\")\n",
    "plt.plot(rec_cal, prec_cal, label=\"NB calibrado\", color=\"blue\")\n",
    "plt.title(\"PR Curve — Naive Bayes\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Calibration Curve\n",
    "plt.subplot(3, 3, 9)\n",
    "pt_raw, pp_raw = calibration_curve(y, proba_nb_norm, n_bins=10)\n",
    "pt_cal, pp_cal = calibration_curve(y, cal_proba_nb_norm, n_bins=10)\n",
    "plt.plot(pp_raw, pt_raw, \"s-\", label=\"NB raw\", color=\"red\")\n",
    "plt.plot(pp_cal, pt_cal, \"o-\", label=\"NB calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"Calibration — Naive Bayes\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "f1af86309b81516f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calibração com o metodo isotonic, que é ideal para uma  quantidade de dados acima de mil\n",
    "#Calibração dos modelos com os dados normalizados\n",
    "\n",
    "cal_rf_norm = CalibratedClassifierCV(rf, cv=5, method='isotonic')\n",
    "cal_proba_rf_norm = cross_val_predict(cal_rf_norm, X_norm, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "cal_auc_rf_norm = roc_auc_score(y, cal_proba_rf_norm)\n",
    "cal_ap_rf_norm = average_precision_score(y, cal_proba_rf_norm)\n",
    "\n",
    "# Logistic Regression com dados normalizados\n",
    "cal_lr_norm = CalibratedClassifierCV(logreg, cv=5, method='isotonic')\n",
    "cal_proba_lr_norm = cross_val_predict(cal_lr_norm, X_norm, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "cal_auc_lr_norm = roc_auc_score(y, cal_proba_lr_norm)\n",
    "cal_ap_lr_norm = average_precision_score(y, cal_proba_lr_norm)\n",
    "\n",
    "# Naive Bayes com dados normalizados\n",
    "cal_nb_norm = CalibratedClassifierCV(nb, cv=5, method='isotonic')\n",
    "cal_proba_nb_norm = cross_val_predict(cal_nb_norm, X_norm, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "cal_auc_nb_norm = roc_auc_score(y, cal_proba_nb_norm)\n",
    "cal_ap_nb_norm = average_precision_score(y, cal_proba_nb_norm)\n",
    "\n",
    "print(\"\\n RESULTADOS COM CALIBRAÇÃO\")\n",
    "print(f\"RF (cal): AUC={cal_auc_rf_norm:.4f}, AP={cal_ap_rf_norm:.4f}\")\n",
    "print(f\"LR (cal): AUC={cal_auc_lr_norm:.4f}, AP={cal_ap_lr_norm:.4f}\")\n",
    "print(f\"NB (cal): AUC={cal_auc_nb_norm:.4f}, AP={cal_ap_nb_norm:.4f}\")\n",
    "\n",
    "print(\"\\n\\nTABELA FINAL\")\n",
    "print(\"-\" * 89)\n",
    "print(f\"{'Modelo':<20}{'AUC_NORM':<15}{'AUC_NORM_CAL':<15}{'AP_NORM':<15}{'AP_NORM_CAL':<15}\")\n",
    "print(\"-\" * 89)\n",
    "print(\n",
    "    f\"{'Random Forest':<20}{auc_rf_norm:.4f}{'':<13}{cal_auc_rf_norm:.4f}{'':<13}{ap_rf_norm:.4f}{'':<13}{cal_ap_rf_norm:.4f}\")\n",
    "print(\n",
    "    f\"{'Logistic Reg.':<25}{auc_lr_norm:.4f}{'':<13}{cal_auc_lr_norm:.4f}{'':<13}{ap_lr_norm:.4f}{'':<13}{cal_ap_lr_norm:.4f}\")\n",
    "print(\n",
    "    f\"{'Naive Bayes':<23}{auc_nb_norm:.4f}{'':<13}{cal_auc_nb_norm:.4f}{'':<13}{ap_nb_norm:.4f}{'':<13}{cal_ap_nb_norm:.4f}\")\n",
    "print(\"-\" * 89)\n",
    "\n",
    "#   PLOTS PARA OS 3 MODELOS: RF, LR, NB\n",
    "#   PLOTS: ROC, PR, CALIBRATION\n",
    "plt.figure(figsize=(18, 12))\n",
    "plt.suptitle(\"Comparação de Modelos — ROC, Precision-Recall e Calibration Curves\",\n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1 — RANDOM FOREST\n",
    "# ROC\n",
    "plt.subplot(3, 3, 1)\n",
    "fpr_raw, tpr_raw, _ = roc_curve(y, proba_rf_norm)\n",
    "fpr_cal, tpr_cal, _ = roc_curve(y, cal_proba_rf_norm)\n",
    "plt.plot(fpr_raw, tpr_raw, label=\"RF raw\", color=\"red\")\n",
    "plt.plot(fpr_cal, tpr_cal, label=\"RF calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC — Random Forest\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Precision–Recall\n",
    "plt.subplot(3, 3, 2)\n",
    "prec_raw, rec_raw, _ = precision_recall_curve(y, proba_rf_norm)\n",
    "prec_cal, rec_cal, _ = precision_recall_curve(y, cal_proba_rf_norm)\n",
    "plt.plot(rec_raw, prec_raw, label=\"RF raw\", color=\"red\")\n",
    "plt.plot(rec_cal, prec_cal, label=\"RF calibrado\", color=\"blue\")\n",
    "plt.title(\"PR Curve — Random Forest\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Calibration Curve\n",
    "plt.subplot(3, 3, 3)\n",
    "pt_raw, pp_raw = calibration_curve(y, proba_rf_norm, n_bins=10)\n",
    "pt_cal, pp_cal = calibration_curve(y, cal_proba_rf_norm, n_bins=10)\n",
    "plt.plot(pp_raw, pt_raw, \"s-\", label=\"RF raw\", color=\"red\")\n",
    "plt.plot(pp_cal, pt_cal, \"o-\", label=\"RF calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"Calibration — Random Forest\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# 2 — LOGISTIC REGRESSION\n",
    "# ROC\n",
    "plt.subplot(3, 3, 4)\n",
    "fpr_raw, tpr_raw, _ = roc_curve(y, proba_lr_norm)\n",
    "fpr_cal, tpr_cal, _ = roc_curve(y, cal_proba_lr_norm)\n",
    "plt.plot(fpr_raw, tpr_raw, label=\"LR raw\", color=\"red\")\n",
    "plt.plot(fpr_cal, tpr_cal, label=\"LR calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC — Logistic Regression\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Precision–Recall\n",
    "plt.subplot(3, 3, 5)\n",
    "prec_raw, rec_raw, _ = precision_recall_curve(y, proba_lr_norm)\n",
    "prec_cal, rec_cal, _ = precision_recall_curve(y, cal_proba_lr_norm)\n",
    "plt.plot(rec_raw, prec_raw, label=\"LR raw\", color=\"red\")\n",
    "plt.plot(rec_cal, prec_cal, label=\"LR calibrado\", color=\"blue\")\n",
    "plt.title(\"PR Curve — Logistic Regression\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Calibration Curve\n",
    "plt.subplot(3, 3, 6)\n",
    "pt_raw, pp_raw = calibration_curve(y, proba_lr_norm, n_bins=10)\n",
    "pt_cal, pp_cal = calibration_curve(y, cal_proba_lr_norm, n_bins=10)\n",
    "plt.plot(pp_raw, pt_raw, \"s-\", label=\"LR raw\", color=\"red\")\n",
    "plt.plot(pp_cal, pt_cal, \"o-\", label=\"LR calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"Calibration — Logistic Regression\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# 3 — NAIVE BAYES\n",
    "# ROC\n",
    "plt.subplot(3, 3, 7)\n",
    "fpr_raw, tpr_raw, _ = roc_curve(y, proba_nb_norm)\n",
    "fpr_cal, tpr_cal, _ = roc_curve(y, cal_proba_nb_norm)\n",
    "plt.plot(fpr_raw, tpr_raw, label=\"NB raw\", color=\"red\")\n",
    "plt.plot(fpr_cal, tpr_cal, label=\"NB calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"ROC — Naive Bayes\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Precision–Recall\n",
    "plt.subplot(3, 3, 8)\n",
    "prec_raw, rec_raw, _ = precision_recall_curve(y, proba_nb_norm)\n",
    "prec_cal, rec_cal, _ = precision_recall_curve(y, cal_proba_nb_norm)\n",
    "plt.plot(rec_raw, prec_raw, label=\"NB raw\", color=\"red\")\n",
    "plt.plot(rec_cal, prec_cal, label=\"NB calibrado\", color=\"blue\")\n",
    "plt.title(\"PR Curve — Naive Bayes\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "# Calibration Curve\n",
    "plt.subplot(3, 3, 9)\n",
    "pt_raw, pp_raw = calibration_curve(y, proba_nb_norm, n_bins=10)\n",
    "pt_cal, pp_cal = calibration_curve(y, cal_proba_nb_norm, n_bins=10)\n",
    "plt.plot(pp_raw, pt_raw, \"s-\", label=\"NB raw\", color=\"red\")\n",
    "plt.plot(pp_cal, pt_cal, \"o-\", label=\"NB calibrado\", color=\"blue\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.title(\"Calibration — Naive Bayes\")\n",
    "plt.grid(True);\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "16ef1a5389ab25f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h3>Calibração das Probabilidades</h3>\n",
    "\n",
    "A probabilidade produzida por um classificador nem sempre representa corretamente a realidade.\n",
    "Modelos como Random Forests, SVMs ou Gradient Boosting tendem a gerar previsões demasiado confiantes, mesmo quando estando erradas.\n",
    "Para corrigir isso, aplica-se um processo de calibração das probabilidades.\n",
    "\n",
    "\n",
    "<b>Método Sigmoid (Platt Scaling)</b>\n",
    "A função sigmoid dada por:\n",
    "$$ p(x)= \\frac{1}{1+e^{A f(x) + B }} $$\n",
    "\n",
    "- f(x) é o output bruto do modelo antes da calibração\n",
    "- A e B são parâmetros aprendidos pelo algoritmo\n",
    "- A sigmoid transforma o output numa probabilidade “corrigida”.\n",
    "-\n",
    "Este método tem duas caraterísticas essenciais, onde paramétrico, ou seja, assume uma curva suave em “S”.\n",
    "Funciona muito bem em datasets pequenos ou médios, como o presente.\n",
    "Evita overfitting, porque a transformação tem apenas dois parâmetros.\n",
    "Por isso é especialmente adequado para:\n",
    "* Random Forests\n",
    "* SVMs\n",
    "* Gradient Boosting\n",
    "* Dados com poucas centenas ou poucos milhares de amostras\n",
    "\n",
    "<b>Método Isotonic</b>\n",
    "Quando as probabilidades são muito irregulares, ou quando se tem muitos dados, é comum usar a Regressão Isotónica.\n",
    "Esta técnica:\n",
    "* não assume nenhum formato específico para a curva;\n",
    "* apenas exige que seja monótona crescente;\n",
    "* ajusta uma função em “degraus”, sendo muito flexível.\n",
    "No entanto não é aramétrica, ou seja pode adaptar-se demasiado aos dados.\n",
    "Ainda dá overfit facilmente quando o dataset é pequeno, normalmente só é recomendado quando existem mais de 1000–5000 amostras.\n",
    "\n",
    "<b>Escolha no contexto deste trabalho</b>\n",
    "\n",
    "O dataset Pima Diabetes tem apenas 768 amostras, o que é considerado um dataset pequeno.\n",
    "Por isso:\n",
    "* O método sigmoid é a escolha correta e mais estável.\n",
    "* O método isotonic tenderia a overfitar, criando uma curva demasiado ajustada ao conjunto de treino, e poranto exibindo valores maiores"
   ],
   "id": "fb52ec42f5299f5d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%%sql\n",
   "id": "22bec25d9d530a4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "###  3. Observações Gerais:",
   "id": "5f0aed647e52f6ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### 1. CLASSIFICADORES:\n",
    "- Melhor desempenho: Logistic Regression\n",
    "- Todos os modelos têm desempenho razoável (AUC > 0.70)\n",
    "\n",
    "##### 2. NORMALIZAÇÃO:\n",
    "- Beneficia classificadores baseados em distância/gradiente\n",
    "- Random Forest é robusto a diferentes escalas\n",
    "\n",
    "##### 3. METODOLOGIA:\n",
    "- Stratified K-Fold garante representatividade das classes\n",
    "- AUC é métrica mais adequada para dados desbalanceados\n",
    "\n",
    "\n",
    "##### 4. CALIBRAÇÃO:\n",
    "- Garante a fildelidade dos valores expostos pelos modelos\n",
    "- Avaliação após a calibração aumentou, excepto na precisão média do Neyve Bayes\n",
    "\n",
    "##### 5. CONSIDERAÇÕES MÉDICAS:\n",
    "- Recall alto é importante (evitar falsos negativos)\n",
    "- Um falso negativo = não detetar diabetes quando existe\n",
    "- Pode ser necessário ajustar limiar de decisão\n"
   ],
   "id": "b19f88cea050ddb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a5f43e76a9134ce",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
